{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "ca2b2d2fad40d0d1113e4fd950a3cdf7c29f62f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/16/6b6898dda4207d3521a600c91bb678b096abc9dc2722ce776842ab8005c8/albumentations-0.2.0.tar.gz (60kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 4.0MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from albumentations) (1.16.2)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from albumentations) (1.1.0)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.6/site-packages (from albumentations) (4.0.0.21)\r\n",
      "Collecting imgaug<0.2.7,>=0.2.5 (from albumentations)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 634kB 24.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scikit-image>=0.11.0 in /opt/conda/lib/python3.6/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.14.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.12.0)\r\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.5.3)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.5.2)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (5.1.0)\r\n",
      "Requirement already satisfied: networkx>=1.8 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.1)\r\n",
      "Requirement already satisfied: dask[array]>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.4)\r\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.2.2)\r\n",
      "Requirement already satisfied: decorator>=4.1.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.3.0)\r\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /opt/conda/lib/python3.6/site-packages (from dask[array]>=1.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.9.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2018.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (39.1.0)\r\n",
      "Building wheels for collected packages: albumentations, imgaug\r\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/92/8d/52/c0c6d4d3f42caafcc27b3b3c5cfe990e59635fe254349c60aa\r\n",
      "  Building wheel for imgaug (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\r\n",
      "Successfully built albumentations imgaug\r\n",
      "Installing collected packages: imgaug, albumentations\r\n",
      "  Found existing installation: imgaug 0.2.8\r\n",
      "    Uninstalling imgaug-0.2.8:\r\n",
      "      Successfully uninstalled imgaug-0.2.8\r\n",
      "Successfully installed albumentations-0.2.0 imgaug-0.2.6\r\n",
      "Collecting kerascv\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/df/725f829ca34c1238af08b8e8506fa87a3c05ad70377ed8eaf3b7ccd1e676/kerascv-0.0.27-py2.py3-none-any.whl (83kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 5.3MB/s \r\n",
      "\u001b[?25hCollecting mxnet\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6d/7932788aea1293015548631495a1b44e588127fedcf4221a5dcdfa411e7b/mxnet-1.4.0.post0-py2.py3-none-manylinux1_x86_64.whl (28.4MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 1.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: keras in /opt/conda/lib/python3.6/site-packages (from kerascv) (2.2.4)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from kerascv) (2.9.0)\r\n",
      "Collecting numpy<1.15.0,>=1.8.2 (from mxnet)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 13.8MB 2.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.6/site-packages (from mxnet) (2.21.0)\r\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from mxnet) (0.8.4)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras->kerascv) (1.0.9)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras->kerascv) (1.1.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras->kerascv) (1.0.7)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras->kerascv) (3.12)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras->kerascv) (1.12.0)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (2.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (2019.3.9)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->mxnet) (1.22)\r\n",
      "\u001b[31mtensorpack 0.9.1 has requirement msgpack-numpy>=0.4.4.2, but you'll have msgpack-numpy 0.4.3.2 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmodes 0.9 has requirement scikit-learn<0.20.0,>=0.19.0, but you'll have scikit-learn 0.20.3 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmeans-smote 0.1.0 has requirement imbalanced-learn<0.4,>=0.3.1, but you'll have imbalanced-learn 0.5.0.dev0 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mkmeans-smote 0.1.0 has requirement scikit-learn<0.20,>=0.19.0, but you'll have scikit-learn 0.20.3 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mfastai 1.0.48 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mcvxpy 1.0.21 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: kerascv, numpy, mxnet\r\n",
      "  Found existing installation: numpy 1.16.2\r\n",
      "    Uninstalling numpy-1.16.2:\r\n",
      "      Successfully uninstalled numpy-1.16.2\r\n",
      "Successfully installed kerascv-0.0.27 mxnet-1.4.0.post0 numpy-1.14.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations \n",
    "!pip install kerascv mxnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepshuffle', 'fdmobilenet', 'histopathologic-cancer-detection']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
    "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
    "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "from keras.layers.pooling import _GlobalPooling1D\n",
    "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.applications.nasnet import NASNetMobile, NASNetLarge, preprocess_input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import *\n",
    "from imgaug import augmenters as iaa\n",
    "from albumentations import Compose, RandomRotate90, Transpose, Flip, OneOf, CLAHE, IAASharpen, IAAEmboss, RandomBrightnessContrast, JpegCompression, Blur, GaussNoise, HueSaturationValue, ShiftScaleRotate, Normalize\n",
    "import imgaug as ia\n",
    "#from shufflenetv2 import ShuffleNetV2\n",
    "from kerascv.model_provider import get_model as kecv_get_model\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "import shutil,math\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "085c0cdb8d9e796967f7cb9ca3aa15d42c21c5e2"
   },
   "outputs": [],
   "source": [
    "img_size_in = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../input/histopathologic-cancer-detection/train_labels.csv\")\n",
    "id_label_map = {k:v for k,v in zip(df_train.id.values, df_train.label.values)}\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4c1169ec9a84704cff822b6e8ba90729d0ee383e"
   },
   "outputs": [],
   "source": [
    "def get_id_from_file_path(file_path):\n",
    "    return file_path.split(os.path.sep)[-1].replace('.tif', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4839c33e47619dfaf0f63d29bcf01ba50a96dfec"
   },
   "outputs": [],
   "source": [
    "labeled_files = glob('../input/histopathologic-cancer-detection/train/*.tif')\n",
    "test_files = glob('../input/histopathologic-cancer-detection/test/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4d3168a806b716023cef1d798b3ede847f7546ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled_files size : 220025\n",
      "test_files size : 57458\n"
     ]
    }
   ],
   "source": [
    "print(\"labeled_files size :\", len(labeled_files))\n",
    "print(\"test_files size :\", len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "af19d597affefcbb1a14e5dd0d591bb3294efb61"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(labeled_files, test_size=0.1, random_state=101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "bd67e144f327114229b410e0af43b71f45ce0d72"
   },
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def do_train_augmentations():\n",
    "    return Compose([\n",
    "        RandomRotate90(p=0.5),\n",
    "        Transpose(p=0.5),\n",
    "        Flip(p=0.5),\n",
    "        OneOf([CLAHE(clip_limit=2),\n",
    "              IAASharpen(),\n",
    "              IAAEmboss(),\n",
    "              RandomBrightnessContrast(),\n",
    "              JpegCompression(),\n",
    "              Blur(),\n",
    "              GaussNoise()],\n",
    "              p=0.5),\n",
    "        HueSaturationValue(p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15, rotate_limit=45, p=0.5),\n",
    "        Normalize(p=1)])\n",
    "\n",
    "\n",
    "def do_inference_aug():\n",
    "    return Compose([Normalize(p=1)], p=1)\n",
    "\n",
    "def data_gen(list_files, id_label_map_in, batch_size_in, img_size_in, aug_funtion):\n",
    "    aug = aug_funtion()\n",
    "    \n",
    "    while True:\n",
    "        shuffle(list_files)\n",
    "        for block in chunker(list_files, batch_size_in):\n",
    "\n",
    "            X = [cv2.resize(cv2.imread(x), (img_size_in, img_size_in)) for x in block]\n",
    "            X = [aug(image=x)['image'] for x in X]\n",
    "\n",
    "            Y = [id_label_map_in[get_id_from_file_path(x)] for x in block]\n",
    "\n",
    "            yield np.array(X), np.array(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bcae07d4c6b095a1584000242780576307d0d286"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    inp_mask = Input(shape=input_shape)\n",
    "    net = kecv_get_model(\"fdmobilenet_w3d4\", pretrained=True)\n",
    "    net.name = 'shufflenet'\n",
    "\n",
    "    x = net(inp_mask)\n",
    "    #x = net.output\n",
    "    #x = Flatten()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    out = Dense(n_out, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp_mask, outputs=[out])\n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "0bf864cbe2060cb9798a348b5f72f67efabc7e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /tmp/.keras/models/fdmobilenet_w3d4-1601-2ea5eba9.h5.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.159/fdmobilenet_w3d4-1601-2ea5eba9.h5.zip...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "shufflenet (Model)           (None, 1000)              1845112   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,425,465\n",
      "Trainable params: 2,412,633\n",
      "Non-trainable params: 12,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_shape=(img_size_in, img_size_in, 3), n_out=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "8334bbf852c9a1a36da98389c9fe41b5ccff6c25"
   },
   "outputs": [],
   "source": [
    "import shutil,math\n",
    "#-----In case you want to use a learning rate scheduler from keras this is a good step decay function to play around with-----#\n",
    "def step_decay(epoch):\n",
    "    initial_lrate=1e-4\n",
    "    drop=0.6\n",
    "    epochs_drop = 3.0\n",
    "    lrate= initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "1a15784bebe57625bf3ae311f272d7016dc9c976"
   },
   "outputs": [],
   "source": [
    "#-------Callbacks-------------#\n",
    "h5_path = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(h5_path, \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "lrsched = LearningRateScheduler(step_decay,verbose=1)\n",
    "\n",
    "callbacks = [checkpoint,lrsched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "db0b06f165a011723aef4266bf1be50b977268c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6188/6188 [==============================] - 1319s 213ms/step - loss: 0.2959 - acc: 0.8813 - val_loss: 0.2667 - val_acc: 0.9084\n",
      "Epoch 2/2\n",
      "4687/6188 [=====================>........] - ETA: 4:22 - loss: 0.2431 - acc: 0.9057"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "#h5_path = \"model.h5\"\n",
    "#checkpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=True,mode='max')\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True\n",
    "model.layers[-7].trainable = True\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    data_gen(train, id_label_map, batch_size,  img_size_in, do_train_augmentations),\n",
    "    validation_data=data_gen(val, id_label_map, batch_size,img_size_in,do_inference_aug),\n",
    "    epochs=2, verbose=1,\n",
    "    #callbacks=[checkpoint],\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    validation_steps=len(val) // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "7a703f31ac14f5a43bd893877c6af7ade0326cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0001.\n",
      "6188/6188 [==============================] - 1157s 187ms/step - loss: 0.1605 - acc: 0.9412 - val_loss: 0.1248 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95756, saving model to model.h5\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0001.\n",
      "6188/6188 [==============================] - 1128s 182ms/step - loss: 0.1579 - acc: 0.9423 - val_loss: 0.1182 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95756 to 0.95885, saving model to model.h5\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 6e-05.\n",
      "1608/6188 [======>.......................] - ETA: 13:08 - loss: 0.1548 - acc: 0.9433"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights(\"../input/fdmobilenet/FD-MobileNet_model.h5\") \n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    data_gen(train, id_label_map, batch_size,  img_size_in, do_train_augmentations),\n",
    "    validation_data=data_gen(val, id_label_map, batch_size,img_size_in,do_inference_aug),\n",
    "    epochs=20, verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    steps_per_epoch=len(train) // batch_size,\n",
    "    validation_steps=len(val) // batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "dfd3c118d1646bb3eef817c42baa98e50632031b"
   },
   "outputs": [],
   "source": [
    "#show_final_history(history)\n",
    "#print(\"Validation Accuracy: \" + str(history.history['val_acc'][-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "c4c3aef0882855069108497c0778f9b833793b5b"
   },
   "outputs": [],
   "source": [
    "#predictions = model.predict_generator(roc_validation_generator, steps=len(roc_validation_generator), verbose=1)\n",
    "#false_positive_rate, true_positive_rate, threshold = roc_curve(roc_validation_generator.classes, predictions)\n",
    "#area_under_curve = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "#plt.plot([0, 1], [0, 1], 'k--')\n",
    "#plt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\n",
    "#plt.xlabel('False positive rate')\n",
    "#plt.ylabel('True positive rate')\n",
    "#plt.title('ROC curve')\n",
    "#plt.legend(loc='best')\n",
    "#plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "d399c51b099a414ef83e9b45a8bafab7206b1c24"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "787cec513417ebb2c703d48b0ba97e1c4344c8d7"
   },
   "outputs": [],
   "source": [
    "for batch in chunker(test_files, batch_size):\n",
    "    X = [preprocess_input(cv2.resize(cv2.imread(x),(img_size_in,img_size_in))) for x in batch]\n",
    "    ids_batch = [get_id_from_file_path(x) for x in batch]\n",
    "    X = np.array(X)\n",
    "    preds_batch = ((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n",
    "    preds += preds_batch\n",
    "    ids += ids_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "1b531bfe1d28a7bae83b74d9f857ae0f7029fdd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d3a0e75dd14a12773d7ad53bda6f1e1c5ba97f5c</td>\n",
       "      <td>0.885244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdb69de941bb1dedf3d15564b39a67dec276f701</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371816c763c118a62ac1f4139f45806167c7e88b</td>\n",
       "      <td>0.011555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d18e5df26368164b4cd531941e489f2f19a5302d</td>\n",
       "      <td>0.680979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d57c22c04cd9c20540edff394de0f50fcdf55d0d</td>\n",
       "      <td>0.992982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id     label\n",
       "0  d3a0e75dd14a12773d7ad53bda6f1e1c5ba97f5c  0.885244\n",
       "1  bdb69de941bb1dedf3d15564b39a67dec276f701  0.000919\n",
       "2  371816c763c118a62ac1f4139f45806167c7e88b  0.011555\n",
       "3  d18e5df26368164b4cd531941e489f2f19a5302d  0.680979\n",
       "4  d57c22c04cd9c20540edff394de0f50fcdf55d0d  0.992982"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'id':ids, 'label':preds})\n",
    "df.to_csv(\"baseline_FD-MobileNet.csv\", index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
